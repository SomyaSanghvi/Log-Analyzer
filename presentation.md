# Java Log Processing System using Streams API

## üìå Problem Statement

Process a large server log file in a memory-efficient way and compute:

- Top 10 slowest endpoints
- Error rate per endpoint
- P95 response time
- Unique active users

Each log line format:

timestamp,userId,endpoint,responseTime,statusCode

---

# üß† Design Overview

We use:

- Java Streams API
- Lazy file streaming (Files.lines)
- Single-pass aggregation
- O(n) time complexity

---

# üìä Metrics Computed

## 1Ô∏è‚É£ Top 10 Slowest Endpoints

Sorted by average response time.

Example Output:

/api/orders -> 1031.67  
/api/products -> 461.25  
/api/login -> 198.33  

### Insight:
Identifies performance bottlenecks.

---

## 2Ô∏è‚É£ Error Rate Per Endpoint

Definition:

errorRate = errorCount / totalRequests  
(statusCode >= 400)

Example:

/api/login -> 0.33  
/api/orders -> 0.33  

### Insight:
Helps detect unstable APIs.

---

## 3Ô∏è‚É£ P95 Response Time

Definition:

95% of requests complete below this latency.

Example:

P95 = 1150 ms

### Why P95?
Average hides tail latency.
P95 captures user experience degradation.

---

## 4Ô∏è‚É£ Unique Active Users

Computed using HashSet.

Example:

Unique Active Users: 546

---

# ‚ö° Streaming vs Loading Entire File

## ‚ùå Loading Entire File

